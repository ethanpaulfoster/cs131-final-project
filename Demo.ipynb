{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibrate camera\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "img = Image.open(\"photodata/drawer0.jpg\")\n",
    "print(f\"Image is {img.width} x {img.height}\")\n",
    "points = np.array(\n",
    "    [\n",
    "        [314.0, 866.0],  # [0]\n",
    "        [290.0, 1388.0],  # [1]\n",
    "        [677.0, 797.0],  # [2]\n",
    "        [463.0, 1583.0],  # [3]\n",
    "        [523.0, 1012.0],  # [4]\n",
    "        [905.0, 914.0],  # [5]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize image & annotated points\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "ax.imshow(img)\n",
    "ax.scatter(points[:, 0], points[:, 1], color=\"white\", marker=\"x\")\n",
    "for i in range(len(points)):\n",
    "    ax.annotate(\n",
    "        f\"points[{i}]\",\n",
    "        points[i] + np.array([15.0, 5.0]),\n",
    "        color=\"white\",\n",
    "        backgroundcolor=(0, 0, 0, 0.15),\n",
    "        zorder=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select points used to compute each vanishing point\n",
    "#\n",
    "# Each `v*_indices` list should contain four integers, corresponding to\n",
    "# indices into the `points` array; the first two ints define one line and\n",
    "# the second two define another line.\n",
    "from calibrate import intersection_from_lines\n",
    "        \n",
    "v0_indices = None\n",
    "v1_indices = None\n",
    "v2_indices = None\n",
    "\n",
    "v0_indices = [0, 1, 3, 4]\n",
    "v1_indices = [0, 2, 4, 5]\n",
    "v2_indices = [0, 4, 2, 5]\n",
    "\n",
    "# Compute vanishing points\n",
    "v = np.zeros((3, 2))\n",
    "v[:, :2] = np.array(\n",
    "    [\n",
    "        intersection_from_lines(*points[v0_indices]),\n",
    "        intersection_from_lines(*points[v1_indices]),\n",
    "        intersection_from_lines(*points[v2_indices]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibrate import optical_center_from_vanishing_points\n",
    "\n",
    "optical_center = optical_center_from_vanishing_points(v[0], v[1], v[2],)\n",
    "c_x, c_y = optical_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibrate import focal_length_from_two_vanishing_points\n",
    "\n",
    "# If your implementation is correct, these should all be ~the same\n",
    "f = focal_length_from_two_vanishing_points(v[0], v[1], optical_center)\n",
    "print(f\"Focal length from v0, v1: {f}\")\n",
    "f = focal_length_from_two_vanishing_points(v[1], v[2], optical_center)\n",
    "print(f\"Focal length from v1, v2: {f}\")\n",
    "f = focal_length_from_two_vanishing_points(v[0], v[2], optical_center)\n",
    "print(f\"Focal length from v0, v2: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying the board coordinates\n",
    "\n",
    "board_z_distance = 384 #(inches)\n",
    "board_coordinates = [882, 925]\n",
    "img = Image.open(\"photodata/divingframe124.jpg\")\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "ax.imshow(img)\n",
    "ax.scatter(board_coordinates[0], board_coordinates[1], color=\"red\", marker=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Keypoints / Box coordinates\n",
    "#POSE ESTIMATION SAVING TO ARRAY\n",
    "from poseEstimation import estimate_pose\n",
    "\n",
    "\n",
    "data_frames, keypoints, boxes = estimate_pose(\"videos/IMG_2478.mov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.rcParams['animation.embed_limit'] = 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8)) \n",
    "\n",
    "im = ax.imshow(np.zeros(data_frames[0].shape, dtype=np.uint8))\n",
    "\n",
    "def init():\n",
    "    im.set_data(np.zeros(data_frames[0].shape, dtype=np.uint8))\n",
    "    return (im,)\n",
    "\n",
    "def update(frame_number):\n",
    "    rgb_image = cv2.cvtColor(data_frames[frame_number], cv2.COLOR_BGR2RGB)\n",
    "    im.set_data(rgb_image)\n",
    "    return (im,)\n",
    "\n",
    "# Create the animation\n",
    "ani_pose = FuncAnimation(fig, update, frames=len(data_frames), init_func=init, interval=50, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani_pose.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Labels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(38, 30)  \n",
    "        self.act1 = nn.ReLU()             \n",
    "        self.hidden2 = nn.Linear(30, 20)  \n",
    "        self.act2 = nn.ReLU()             \n",
    "        self.output = nn.Linear(20, 3)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))    \n",
    "        x = self.act2(self.hidden2(x))    \n",
    "        x = self.output(x)       \n",
    "        return x\n",
    "    \n",
    "model = Multiclass()  # Re-create the model structure\n",
    "model.load_state_dict(torch.load('model_best_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import HTML\n",
    "from projection import diver_height_and_distance\n",
    "\n",
    "# Assuming data_frames is your list of frames in BGR format\n",
    "\n",
    "plt.rcParams['animation.embed_limit'] = 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(np.zeros(data_frames[0].shape, dtype=np.uint8))\n",
    "\n",
    "# Placeholder prediction display text\n",
    "prediction_text = ax.text(10, 10, '', fontsize=18, color='black')\n",
    "height_text = ax.text(10, 10, '', fontsize=18, color='black')\n",
    "distance_text = ax.text(10, 10, '', fontsize=18, color='black')\n",
    "\n",
    "\n",
    "\n",
    "def get_model_prediction(keypoints, boxes):\n",
    "    positions = [\"Not in air\", \"Straight\", \"Pike\"]\n",
    "    # Placeholder for your model's prediction logic\n",
    "    # Use the keypoints as input to your model and return the prediction\n",
    "    if keypoints.size()[1] == 17:\n",
    "        currKeypoints = keypoints[0]\n",
    "        currBoxes = boxes\n",
    "        combined = torch.cat((torch.flatten(currKeypoints), currBoxes))\n",
    "        prediction = model(combined)\n",
    "        prediction = torch.argmax(prediction)\n",
    "        return positions[prediction]\n",
    "    return \"No detection\"\n",
    "\n",
    "def get_height_distance(boxes, f, c_x, c_y, board_z_distance, board_coordinates):\n",
    "    x = int(boxes[0] + boxes[2]) / 2\n",
    "    y = int(boxes[1] + boxes[3]) / 2\n",
    "    diver_coordinates = [x, y]\n",
    "    height, distance = diver_height_and_distance(board_coordinates, diver_coordinates, f, c_x, c_y, board_z_distance)\n",
    "    height = \"height: \" + str(round(height / 12, 1)) + \" ft\"\n",
    "    distance = \"distance: \" + str(round(distance / 12, 1)) + \" ft\"\n",
    "    return height, distance\n",
    "\n",
    "def init():\n",
    "    im.set_data(np.zeros(data_frames[0].shape, dtype=np.uint8))\n",
    "    prediction_text.set_text('')\n",
    "    return (im, prediction_text)\n",
    "\n",
    "def update(frame_number):\n",
    "    rgb_image = cv2.cvtColor(data_frames[frame_number], cv2.COLOR_BGR2RGB)\n",
    "    im.set_data(rgb_image)\n",
    "    \n",
    "    # Get model prediction for current frame\n",
    "    prediction = get_model_prediction(keypoints[frame_number], boxes[frame_number])\n",
    "    prediction_text.set_text(prediction)\n",
    "    height, distance = get_height_distance(boxes[frame_number], f, c_x, c_y, board_z_distance, board_coordinates)\n",
    "    height_text.set_text(height)\n",
    "    distance_text.set_text(distance)\n",
    "    \n",
    "    # Optionally, adjust the position of your text if needed\n",
    "    prediction_text.set_position((100, 100))\n",
    "    height_text.set_position((100, 200))\n",
    "    distance_text.set_position((100, 300))\n",
    "    \n",
    "    \n",
    "    return (im, prediction_text)\n",
    "\n",
    "ani_pred = FuncAnimation(fig, update, frames=len(data_frames), init_func=init, interval=50, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(ani_pred.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
